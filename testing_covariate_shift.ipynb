{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import requests\n",
    "import streamlit as st\n",
    "from ensmallen import HyperSketchingPy\n",
    "from grape import Graph\n",
    "from src.models import LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "URL_CLASSYFIRE = \"https://structure.gnps2.org/classyfire?smiles=\"\n",
    "URL_NP_CLASSIFIER = \"https://npclassifier.gnps2.org/classify?smiles=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_np_classifier(compound: str) -> int:\n",
    "    \"\"\"Submit a compound information to the NP Classifier service for evaluation\n",
    "    and receive the classification of the compound.\n",
    "\n",
    "    :param compound: The SMILES of the compound of interest\n",
    "    :type compound: str\n",
    "    :return: A dictionary with the results of the classification\n",
    "    :rtype: dict\n",
    "\n",
    "    >>> classify_with_np_classifier('CCC')\n",
    "\n",
    "    \"\"\"\n",
    "    r = requests.get(\n",
    "        URL_NP_CLASSIFIER + compound,\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightGBM.load_model(\"lightgbm_model_new.pkl\")\n",
    "graph = Graph.from_csv(\n",
    "    name=\"full_graph_clean\",\n",
    "    node_path=\"./data/full_graph_clean_nodes.csv\",\n",
    "    edge_path=\"./data/full_graph_clean_edges.csv\",\n",
    "    node_list_separator=\"\\t\",\n",
    "    node_list_header=True,\n",
    "    nodes_column_number=0,\n",
    "    node_list_node_types_column_number=1,\n",
    "    edge_list_separator=\"\\t\",\n",
    "    edge_list_header=True,\n",
    "    sources_column_number=0,\n",
    "    destinations_column_number=1,\n",
    "    edge_list_edge_types_column_number=2,\n",
    "    directed=False,\n",
    "    load_edge_list_in_parallel=False,\n",
    "    load_node_list_in_parallel=False,\n",
    ")\n",
    "\n",
    "species_phylo = pd.read_csv(\"./data/species/full_wikidata_taxonomy_nodes.csv\")\n",
    "\n",
    "lotus = pl.read_csv(\n",
    "    \"data/molecules/230106_frozen_metadata.csv.gz\",\n",
    "    dtypes={\n",
    "        \"structure_xlogp\": pl.Float32,\n",
    "        \"structure_cid\": pl.UInt32,\n",
    "        \"organism_taxonomy_ncbiid\": pl.UInt32,\n",
    "        \"organism_taxonomy_ottid\": pl.UInt32,\n",
    "        \"structure_stereocenters_total\": pl.UInt32,\n",
    "        \"structure_stereocenters_unspecified\": pl.UInt32,\n",
    "    },\n",
    "    infer_schema_length=50000,\n",
    "    null_values=[\"\", \"NA\"],\n",
    ")\n",
    "\n",
    "lotus = lotus.with_columns(\n",
    "    pl.col(\"organism_taxonomy_gbifid\")\n",
    "    .map_elements(lambda x: np.nan if x.startswith(\"c(\") else x, return_dtype=pl.UInt32)\n",
    "    .alias(\"organism_taxonomy_gbifid\")\n",
    ")\n",
    "lotus = lotus.with_columns(\n",
    "    (\"wd:\" + pl.col(\"organism_wikidata\").str.extract(r\"(Q\\d+)\")).alias(\"wd_species\")\n",
    ")\n",
    "\n",
    "lotus = lotus.with_columns(\n",
    "    (\"wd:\" + pl.col(\"structure_wikidata\").str.extract(r\"(Q\\d+)\")).alias(\"wd_molecule\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound = \"CC(C)CCC(C)C(=O)NCCCNC(=N)N\"\n",
    "dct = classify_with_np_classifier(compound)\n",
    "_ = dct.pop(\"isglycoside\")\n",
    "\n",
    "# We first create the edges dataframe\n",
    "edges_np_classifier = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame([compound]),\n",
    "            pd.DataFrame.from_dict(dct, orient=\"index\"),\n",
    "        ]\n",
    "    )\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "edges_np_classifier[1] = edges_np_classifier.iloc[:, 0].shift(-1)\n",
    "edges_np_classifier.dropna(inplace=True)\n",
    "edges_np_classifier.rename(columns={0: \"child\", 1: \"parent\"}, inplace=True)\n",
    "edges_np_classifier[\"type\"] = \"biolink:subclass_of\"\n",
    "\n",
    "# then the nodes dataframe\n",
    "nodes_np_classifier = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"node\": pd.concat([edges_np_classifier.child, edges_np_classifier.parent]),\n",
    "            \"type\": \"biolink:ChemicalEntity\",\n",
    "        }\n",
    "    )\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_np_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we add the edges of similarity between molecules using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from src.utils import calculate_fingerprint_parallel\n",
    "from src.utils import calculate_fingerprint\n",
    "\n",
    "lotus_pd = pd.read_csv(\n",
    "    \"./data/molecules/230106_frozen_metadata.csv.gz\", low_memory=False\n",
    ")\n",
    "\n",
    "lotus_pd[\"wd_molecule\"] = \"wd:\" + lotus_pd.structure_wikidata.str.extract(r\"(Q\\d+)\")\n",
    "\n",
    "wd_pd = (\n",
    "    lotus_pd[\n",
    "        [\n",
    "            \"wd_molecule\",\n",
    "            \"structure_smiles_2D\",\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(subset=[\"wd_molecule\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "index = wd_pd.wd_molecule.str.extract(r\"wd:Q(\\d+)\").astype(\"int64\").sort_values(0).index\n",
    "wd_pd = wd_pd.reindex(index).reset_index(drop=True)\n",
    "\n",
    "embedding_full = np.array(\n",
    "    calculate_fingerprint_parallel(wd_pd[\"structure_smiles_2D\"].values, radi=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = len(embedding_full)\n",
    "\n",
    "embedding = embedding_full[:SIZE].astype(np.float32)\n",
    "\n",
    "d = embedding.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatIP(d)\n",
    "faiss.normalize_L2(embedding)\n",
    "index.add(embedding)\n",
    "\n",
    "\n",
    "embedding_compound = (\n",
    "    calculate_fingerprint(compound, radi=2).astype(np.float32).reshape(1, -1)\n",
    ")\n",
    "faiss.normalize_L2(embedding_compound)\n",
    "D, I = index.search(embedding_compound.reshape(1, -1), SIZE)\n",
    "out_array = D.reshape(-1)[np.argsort(I.reshape(-1))].astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.DataFrame(\n",
    "    out_array.reshape(1, -1),\n",
    "    columns=[\n",
    "        wd_pd[\"wd_molecule\"].values[i] for i in range(len(wd_pd[\"wd_molecule\"].values))\n",
    "    ],\n",
    "    index=[compound],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table to get index in one columns, the column names in an other columns and the intersection values in the last column\n",
    "edges = edges.stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.rename(\n",
    "    columns={\"level_0\": \"child\", \"level_1\": \"parent\", 0: \"similarity\"}, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_filtered = edges[edges.similarity > 0.96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_filtered.drop(columns=[\"similarity\"], inplace=True)\n",
    "edges_filtered[\"type\"] = \"biolink:similar_to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_add = pd.concat([edges_filtered, edges_np_classifier])\n",
    "nodes_to_add = pd.DataFrame(\n",
    "    {\n",
    "        \"node\": pd.concat([edges_to_add.child, edges_to_add.parent]),\n",
    "        \"type\": \"biolink:ChemicalEntity\",\n",
    "    }\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_np_classifier = Graph.from_pd(\n",
    "    directed=False,\n",
    "    edges_df=edges_to_add,\n",
    "    nodes_df=nodes_to_add,\n",
    "    node_name_column=\"node\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"child\",\n",
    "    edge_dst_column=\"parent\",\n",
    "    edge_type_column=\"type\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_merged = graph | graph_np_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotus_filtered = lotus.select(\n",
    "    [\n",
    "        \"wd_species\",\n",
    "        \"organism_wikidata\",\n",
    "        \"organism_name\",\n",
    "        \"organism_taxonomy_01domain\",\n",
    "        \"organism_taxonomy_02kingdom\",\n",
    "        \"organism_taxonomy_03phylum\",\n",
    "        \"organism_taxonomy_04class\",\n",
    "        \"organism_taxonomy_05order\",\n",
    "        \"organism_taxonomy_06family\",\n",
    "        \"organism_taxonomy_08genus\",\n",
    "        \"organism_taxonomy_09species\",\n",
    "        \"organism_taxonomy_gbifid\",\n",
    "        \"organism_taxonomy_ncbiid\",\n",
    "        \"organism_taxonomy_ottid\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "lotus_filtered = lotus_filtered.unique().to_pandas()\n",
    "lotus_filtered = lotus_filtered.sample(3000)\n",
    "lotus_filtered[\"molecule\"] = compound\n",
    "species_to_remove = list(set(lotus_filtered.wd_species) - set(species_phylo.node))\n",
    "lotus_filtered = lotus_filtered[~lotus_filtered.wd_species.isin(species_to_remove)]\n",
    "molecules_id = graph_merged.get_node_ids_from_node_names(lotus_filtered.molecule)\n",
    "species_id = graph_merged.get_node_ids_from_node_names(lotus_filtered.wd_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotus_filtered.molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketching_features = HyperSketchingPy(\n",
    "    hops=2,\n",
    "    normalize=False,\n",
    "    graph=graph_merged,\n",
    ")\n",
    "sketching_features.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_sketching_unknown = sketching_features.unknown(\n",
    "    sources=molecules_id.astype(\"uint32\"),\n",
    "    destinations=species_id.astype(\"uint32\"),\n",
    "    feature_combination=\"addition\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotus_filtered = lotus.select(\n",
    "    [\n",
    "        \"wd_species\",\n",
    "        \"wd_molecule\",\n",
    "    ]\n",
    ")\n",
    "lotus_filtered = lotus_filtered.unique().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotus_filtered = lotus_filtered.sample(3000)\n",
    "species_to_remove = list(set(lotus_filtered.wd_species) - set(species_phylo.node))\n",
    "lotus_filtered = lotus_filtered[~lotus_filtered.wd_species.isin(species_to_remove)]\n",
    "molecules_id = graph_merged.get_node_ids_from_node_names(lotus_filtered.wd_molecule)\n",
    "species_id = graph_merged.get_node_ids_from_node_names(lotus_filtered.wd_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sketching features\n",
    "pair_sketching_positive = sketching_features.unknown(\n",
    "    sources=molecules_id.astype(\"uint32\"),\n",
    "    destinations=species_id.astype(\"uint32\"),\n",
    "    feature_combination=\"addition\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = graph_merged.filter_from_names(\n",
    "    edge_type_names_to_keep=[\"biolink:in_taxon\"],\n",
    ")\n",
    "neg = pos.sample_negative_graph(\n",
    "    number_of_negative_samples=3000,\n",
    "    sample_edge_types=False,\n",
    "    only_from_same_component=False,\n",
    "    use_scale_free_distribution=True,\n",
    "    random_state=23391 * (3 + 1),\n",
    ")\n",
    "\n",
    "neg_sources = neg.get_directed_source_node_ids()\n",
    "neg_destinations = neg.get_directed_destination_node_ids()\n",
    "sk_negative_features = sketching_features.unknown(\n",
    "    sources=neg_sources,\n",
    "    destinations=neg_destinations,\n",
    "    feature_combination=\"addition\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    ")\n",
    "X = np.concatenate(\n",
    "    [\n",
    "        pair_sketching_unknown,\n",
    "        sk_negative_features,\n",
    "        pair_sketching_positive,\n",
    "    ]\n",
    ")\n",
    "X_embedded = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(X_embedded, columns=[\"x\", \"y\"])\n",
    "df[\"label\"] = (\n",
    "    [\"unknown\"] * pair_sketching_unknown.shape[0]\n",
    "    + [\"negative\"] * sk_negative_features.shape[0]\n",
    "    + [\"positive\"] * pair_sketching_positive.shape[0]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"label\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_merged.get_neighbour_node_names_from_node_name(compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    model.predict_proba(pair_sketching_positive)[:, 1],\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    model.predict_proba(pair_sketching_unknown)[:, 1],\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    model.predict_proba(sk_negative_features)[:, 1],\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to add an edge from the compound \"CC(C)CCC(C)C(=O)NCCCNC(=N)N\" to a species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_np_classifier_new = pd.concat(\n",
    "    [\n",
    "        edges_np_classifier,\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"child\": [\"CC(C)CCC(C)C(=O)NCCCNC(=N)N\"],\n",
    "                \"parent\": [\"wd:Q25834677\"],\n",
    "                \"type\": [\"biolink:in_taxon\"],\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_np_classifier_new = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"node\": pd.concat(\n",
    "                [edges_np_classifier_new.child, edges_np_classifier_new.parent]\n",
    "            ),\n",
    "            \"type\": \"biolink:ChemicalEntity\",\n",
    "        }\n",
    "    )\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "nodes_np_classifier_new.iloc[4, 1] = \"biolink:OrganismTaxon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_np_classifier_new = Graph.from_pd(\n",
    "    directed=False,\n",
    "    edges_df=edges_np_classifier_new,\n",
    "    nodes_df=nodes_np_classifier_new,\n",
    "    node_name_column=\"node\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"child\",\n",
    "    edge_dst_column=\"parent\",\n",
    "    edge_type_column=\"type\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_merged_new = graph | graph_np_classifier_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotus_filtered = lotus.select(\n",
    "    [\n",
    "        \"wd_species\",\n",
    "        \"organism_wikidata\",\n",
    "        \"organism_name\",\n",
    "        \"organism_taxonomy_01domain\",\n",
    "        \"organism_taxonomy_02kingdom\",\n",
    "        \"organism_taxonomy_03phylum\",\n",
    "        \"organism_taxonomy_04class\",\n",
    "        \"organism_taxonomy_05order\",\n",
    "        \"organism_taxonomy_06family\",\n",
    "        \"organism_taxonomy_08genus\",\n",
    "        \"organism_taxonomy_09species\",\n",
    "        \"organism_taxonomy_gbifid\",\n",
    "        \"organism_taxonomy_ncbiid\",\n",
    "        \"organism_taxonomy_ottid\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "lotus_filtered = lotus_filtered.unique().to_pandas()\n",
    "lotus_filtered = lotus_filtered.sample(3000)\n",
    "lotus_filtered[\"molecule\"] = compound\n",
    "species_to_remove = list(set(lotus_filtered.wd_species) - set(species_phylo.node))\n",
    "lotus_filtered = lotus_filtered[~lotus_filtered.wd_species.isin(species_to_remove)]\n",
    "molecules_id = graph_merged.get_node_ids_from_node_names(lotus_filtered.molecule)\n",
    "species_id = graph_merged.get_node_ids_from_node_names(lotus_filtered.wd_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketching_features = HyperSketchingPy(\n",
    "    hops=2,\n",
    "    normalize=False,\n",
    "    graph=graph_merged_new,\n",
    ")\n",
    "sketching_features.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sketching features\n",
    "pair_sketching_unknown = sketching_features.unknown(\n",
    "    sources=molecules_id.astype(\"uint32\"),\n",
    "    destinations=species_id.astype(\"uint32\"),\n",
    "    feature_combination=\"addition\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    model.predict_proba(pair_sketching_unknown)[:, 1],\n",
    "    bins=50,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lotus-hypersketching-ruHkzsWs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
